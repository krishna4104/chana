{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ¾ Chana Quality Classifier - RF-DETR Training (SOTA)\n",
        "\n",
        "Train RF-DETR (State-of-the-Art) model for chana quality detection.\n",
        "\n",
        "**RF-DETR**: First real-time model to achieve 60+ mAP on COCO!\n",
        "\n",
        "**Dataset**: 35,019 images, 9 classes\n",
        "\n",
        "**Runtime**: Select GPU (Runtime â†’ Change runtime type â†’ T4 GPU or A100 recommended)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Setup Environment"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install RF-DETR\n",
        "!pip install rfdetr -q\n",
        "!pip install pycocotools -q\n",
        "print(\"RF-DETR installed!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Mount Google Drive & Load Dataset"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip COCO format dataset from Google Drive\n",
        "# Make sure you uploaded dataset_coco.zip to your Drive root\n",
        "!unzip -q /content/drive/MyDrive/dataset_coco.zip -d /content/\n",
        "print(\"Dataset extracted!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify COCO format dataset structure\n",
        "!ls /content/dataset_coco/\n",
        "!ls /content/dataset_coco/train/\n",
        "!echo \"Train images:\" && ls /content/dataset_coco/train/*.jpg 2>/dev/null | wc -l || find /content/dataset_coco/train -name '*.jpg' | wc -l"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Convert YOLO to COCO Format (if needed)\n",
        "\n",
        "Run this section ONLY if you uploaded YOLO format dataset instead of COCO format."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Skip if you already have COCO format!\n",
        "# This converts YOLO format to COCO JSON format\n",
        "\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "CLASS_NAMES = [\n",
        "    \"Bad Black Channa\",\n",
        "    \"Bad Kabuli Chana\",\n",
        "    \"Good Black Channa\",\n",
        "    \"Good Kabuli Chana\",\n",
        "    \"foreign material\",\n",
        "    \"Bad Soya\",\n",
        "    \"Good Soya\",\n",
        "    \"Bad Matar\",\n",
        "    \"Good Matar\"\n",
        "]\n",
        "\n",
        "def yolo_to_coco(yolo_dir, output_dir, split):\n",
        "    \"\"\"Convert YOLO format to COCO JSON format.\"\"\"\n",
        "    images_dir = os.path.join(yolo_dir, split, 'images')\n",
        "    labels_dir = os.path.join(yolo_dir, split, 'labels')\n",
        "    \n",
        "    os.makedirs(os.path.join(output_dir, split), exist_ok=True)\n",
        "    \n",
        "    coco = {\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": [{\"id\": i, \"name\": name} for i, name in enumerate(CLASS_NAMES)]\n",
        "    }\n",
        "    \n",
        "    ann_id = 1\n",
        "    \n",
        "    image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
        "    \n",
        "    for img_id, img_file in enumerate(tqdm(image_files, desc=f\"Converting {split}\"), 1):\n",
        "        img_path = os.path.join(images_dir, img_file)\n",
        "        label_path = os.path.join(labels_dir, img_file.replace('.jpg', '.txt'))\n",
        "        \n",
        "        # Get image dimensions\n",
        "        with Image.open(img_path) as img:\n",
        "            width, height = img.size\n",
        "        \n",
        "        # Copy image to output\n",
        "        import shutil\n",
        "        shutil.copy(img_path, os.path.join(output_dir, split, img_file))\n",
        "        \n",
        "        coco[\"images\"].append({\n",
        "            \"id\": img_id,\n",
        "            \"file_name\": img_file,\n",
        "            \"width\": width,\n",
        "            \"height\": height\n",
        "        })\n",
        "        \n",
        "        # Parse YOLO labels\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) >= 5:\n",
        "                        class_id = int(parts[0])\n",
        "                        x_center, y_center, w, h = map(float, parts[1:5])\n",
        "                        \n",
        "                        # Convert to COCO format (absolute coordinates)\n",
        "                        x = (x_center - w/2) * width\n",
        "                        y = (y_center - h/2) * height\n",
        "                        w = w * width\n",
        "                        h = h * height\n",
        "                        \n",
        "                        coco[\"annotations\"].append({\n",
        "                            \"id\": ann_id,\n",
        "                            \"image_id\": img_id,\n",
        "                            \"category_id\": class_id,\n",
        "                            \"bbox\": [x, y, w, h],\n",
        "                            \"area\": w * h,\n",
        "                            \"iscrowd\": 0\n",
        "                        })\n",
        "                        ann_id += 1\n",
        "    \n",
        "    # Save COCO JSON\n",
        "    json_path = os.path.join(output_dir, split, '_annotations.coco.json')\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(coco, f)\n",
        "    \n",
        "    print(f\"{split}: {len(coco['images'])} images, {len(coco['annotations'])} annotations\")\n",
        "\n",
        "# Convert all splits\n",
        "YOLO_DIR = '/content/dataset'\n",
        "COCO_DIR = '/content/dataset_coco'\n",
        "\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    yolo_to_coco(YOLO_DIR, COCO_DIR, split)\n",
        "\n",
        "print(\"\\nConversion complete!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train RF-DETR"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from rfdetr import RFDETRBase\n",
        "from rfdetr.util.coco_classes import COCO_CLASSES\n",
        "\n",
        "# Initialize model\n",
        "model = RFDETRBase()\n",
        "\n",
        "# Train\n",
        "model.train(\n",
        "    dataset_dir=\"/content/dataset_coco\",\n",
        "    epochs=50,                    # Increase for better results\n",
        "    batch_size=8,                 # Reduce if OOM (T4 = 8, A100 = 16)\n",
        "    grad_accum_steps=4,           # Effective batch = 8*4 = 32\n",
        "    lr=1e-4,\n",
        "    output_dir=\"/content/drive/MyDrive/chana_models/rfdetr_v1\",\n",
        "    checkpoint_freq=10,\n",
        "    use_ema=True,\n",
        "    use_wandb=False,              # Set True for logging\n",
        ")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluate on Test Set"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "from rfdetr import RFDETRBase\n",
        "\n",
        "model = RFDETRBase()\n",
        "model.load(\"/content/drive/MyDrive/chana_models/rfdetr_v1/best.pt\")\n",
        "\n",
        "# Evaluate\n",
        "results = model.evaluate(\n",
        "    dataset_dir=\"/content/dataset_coco\",\n",
        "    split=\"test\"\n",
        ")\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"mAP50: {results['map50']:.4f}\")\n",
        "print(f\"mAP50-95: {results['map']:.4f}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Test Inference"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Get random test image\n",
        "test_dir = '/content/dataset_coco/test'\n",
        "test_images = [f for f in os.listdir(test_dir) if f.endswith('.jpg')]\n",
        "random_img = random.choice(test_images)\n",
        "img_path = os.path.join(test_dir, random_img)\n",
        "\n",
        "# Run inference\n",
        "image = Image.open(img_path)\n",
        "detections = model.predict(image, threshold=0.5)\n",
        "\n",
        "# Draw results\n",
        "import numpy as np\n",
        "img = np.array(image)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "CLASS_NAMES = [\n",
        "    \"Bad Black Channa\", \"Bad Kabuli Chana\", \"Good Black Channa\",\n",
        "    \"Good Kabuli Chana\", \"foreign material\", \"Bad Soya\",\n",
        "    \"Good Soya\", \"Bad Matar\", \"Good Matar\"\n",
        "]\n",
        "\n",
        "for det in detections:\n",
        "    x1, y1, x2, y2 = map(int, det['bbox'])\n",
        "    cls = det['class_id']\n",
        "    conf = det['confidence']\n",
        "    label = f\"{CLASS_NAMES[cls]}: {conf:.2f}\"\n",
        "    \n",
        "    color = (0, 255, 0) if 'Good' in CLASS_NAMES[cls] else (0, 0, 255)\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "    cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Export Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to ONNX\n",
        "model.export(\n",
        "    format=\"onnx\",\n",
        "    output_path=\"/content/drive/MyDrive/chana_models/rfdetr_v1/model.onnx\"\n",
        ")\n",
        "print(\"Model exported to ONNX!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Download Trained Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/chana_models/rfdetr_v1/best.pt')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
